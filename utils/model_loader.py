# utils/model_loader.py
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Bio-ML Agent â€” Model YÃ¼kleme & Tahmin Utility'si
#
#  KullanÄ±m:
#    from utils.model_loader import load_and_predict, model_info
#
#    # Model bilgisi
#    model_info("results/best_model.pkl")
#
#    # Tahmin yap
#    predictions = load_and_predict("results/best_model.pkl", X_new)
#
#    # Standalone CLI:
#    python utils/model_loader.py --model results/best_model.pkl --data test.csv
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import json
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

import numpy as np


def load_model(model_path: str) -> Any:
    """
    KaydedilmiÅŸ bir modeli yÃ¼kler.

    Args:
        model_path: .pkl dosya yolu

    Returns:
        YÃ¼klenmiÅŸ model (sklearn Pipeline veya Estimator)

    Raises:
        FileNotFoundError: Model dosyasÄ± bulunamadÄ±ysa
    """
    import joblib

    path = Path(model_path)
    if not path.exists():
        raise FileNotFoundError(f"Model dosyasÄ± bulunamadÄ±: {model_path}")

    model = joblib.load(path)
    return model


def model_info(model_path: str) -> Dict[str, Any]:
    """
    KaydedilmiÅŸ modelin meta bilgilerini dÃ¶ndÃ¼rÃ¼r.

    Args:
        model_path: .pkl dosya yolu

    Returns:
        Meta veri dict'i (model adÄ±, gÃ¶rev tÃ¼rÃ¼, metrikler vb.)
    """
    path = Path(model_path)
    meta_path = path.parent / path.name.replace(".pkl", "_meta.json")

    info: Dict[str, Any] = {"model_path": str(path)}

    if meta_path.exists():
        meta = json.loads(meta_path.read_text(encoding="utf-8"))
        info.update(meta)
    else:
        info["warning"] = "Meta veri dosyasÄ± bulunamadÄ±"

    # Model tipini kontrol et
    if path.exists():
        model = load_model(str(path))
        info["model_type"] = type(model).__name__

        # Pipeline ise iÃ§indeki model adÄ±nÄ± al
        if hasattr(model, "named_steps"):
            step_names = list(model.named_steps.keys())
            info["pipeline_steps"] = step_names
            # Son adÄ±m genelde model
            last_step = model.named_steps[step_names[-1]]
            info["estimator_type"] = type(last_step).__name__

    return info


def load_and_predict(
    model_path: str,
    X: np.ndarray,
    return_proba: bool = False,
) -> np.ndarray:
    """
    KaydedilmiÅŸ modeli yÃ¼kleyip tahmin yapar.

    Args:
        model_path: .pkl dosya yolu
        X: Tahmin yapÄ±lacak Ã¶zellik matrisi (n_samples, n_features)
        return_proba: True ise olasÄ±lÄ±k tahmini dÃ¶ndÃ¼r (sadece sÄ±nÄ±flandÄ±rma)

    Returns:
        Tahmin sonuÃ§larÄ± (np.ndarray)
    """
    model = load_model(model_path)

    if return_proba and hasattr(model, "predict_proba"):
        return model.predict_proba(X)

    return model.predict(X)


def predict_single(
    model_path: str,
    features: dict,
    feature_names: list,
) -> Tuple[Any, Optional[np.ndarray]]:
    """
    Tek bir Ã¶rnek iÃ§in tahmin yapar.

    Args:
        model_path: .pkl dosya yolu
        features: {Ã¶zellik_adÄ±: deÄŸer} sÃ¶zlÃ¼ÄŸÃ¼
        feature_names: EÄŸitimde kullanÄ±lan Ã¶zellik sÄ±rasÄ±nÄ± belirten liste

    Returns:
        (tahmin, olasÄ±lÄ±klar) tuple'Ä±

    KullanÄ±m:
        prediction, proba = predict_single(
            "results/best_model.pkl",
            {"radius_mean": 14.2, "texture_mean": 19.5, ...},
            feature_names=["radius_mean", "texture_mean", ...]
        )
    """
    # Ã–zellik vektÃ¶rÃ¼nÃ¼ doÄŸru sÄ±rayla oluÅŸtur
    X = np.array([[features.get(name, 0) for name in feature_names]])

    model = load_model(model_path)
    prediction = model.predict(X)[0]

    proba = None
    if hasattr(model, "predict_proba"):
        proba = model.predict_proba(X)[0]

    return prediction, proba


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Standalone CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    import argparse

    import pandas as pd

    parser = argparse.ArgumentParser(description="Model YÃ¼kleme & Tahmin AracÄ±")
    subparsers = parser.add_subparsers(dest="command", help="Komut")

    # info komutu
    info_parser = subparsers.add_parser("info", help="Model bilgilerini gÃ¶ster")
    info_parser.add_argument("--model", required=True, help=".pkl dosya yolu")

    # predict komutu
    predict_parser = subparsers.add_parser("predict", help="Tahmin yap")
    predict_parser.add_argument("--model", required=True, help=".pkl dosya yolu")
    predict_parser.add_argument("--data", required=True, help="CSV dosya yolu")
    predict_parser.add_argument("--output", default=None, help="Ã‡Ä±ktÄ± CSV yolu")
    predict_parser.add_argument("--sep", default=",", help="CSV ayÄ±rÄ±cÄ±")

    args = parser.parse_args()

    if args.command == "info":
        info = model_info(args.model)
        print("\nðŸ§  Model Bilgileri:")
        print("â”€" * 40)
        for k, v in info.items():
            print(f"  {k}: {v}")

    elif args.command == "predict":
        print(f"ðŸ“‚ Veri yÃ¼kleniyor: {args.data}")
        df = pd.read_csv(args.data, sep=args.sep)
        print(f"   Boyut: {df.shape[0]} satÄ±r Ã— {df.shape[1]} sÃ¼tun")

        predictions = load_and_predict(args.model, df.values)
        df["prediction"] = predictions

        if args.output:
            df.to_csv(args.output, index=False)
            print(f"ðŸ’¾ Tahminler kaydedildi: {args.output}")
        else:
            print("\nðŸ“Š Tahmin SonuÃ§larÄ±:")
            print(df[["prediction"]].value_counts() if len(df) > 10 else df)

    else:
        parser.print_help()

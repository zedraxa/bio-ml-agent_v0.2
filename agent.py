import argparse
import json
import logging
import logging.handlers
import os
import re
import subprocess
import sys
import textwrap
import time
import uuid
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Tuple

import ollama

from llm_backend import (
    LLMBackend, OllamaBackend, auto_create_backend, detect_backend_name,
)

from utils.config import load_config, get_config, Config as AppConfig
from exceptions import (
    ToolExecutionError,
    FileOperationError,
    SecurityViolationError,
    AgentError,
    ToolTimeoutError,
    ValidationError,
    LLMConnectionError,
)
from progress import Spinner
from llm_backend import LLMBackend, OllamaBackend, auto_create_backend
from plugin_manager import PluginManager
from dataset_catalog import format_catalog_for_prompt
from rag_engine import RAGEngine

# â”€â”€ YapÄ±landÄ±rma Ã¼zerinden okunan sabitler â”€â”€
# Bu deÄŸerler config.yaml / env / CLI'dan yÃ¼klenir.
# Ä°lk eriÅŸimde varsayÄ±lanlar kullanÄ±lÄ±r, main() iÃ§inde gÃ¼ncellenir.
_app_cfg = None  # load_config() sonrasÄ± set edilir

def _cfg() -> "AppConfig":
    """Mevcut config'i dÃ¶ndÃ¼rÃ¼r (lazy init)."""
    global _app_cfg
    if _app_cfg is None:
        _app_cfg = get_config()
    return _app_cfg

# Geriye dÃ¶nÃ¼k uyumluluk sabitleri (testler ve diÄŸer modÃ¼ller iÃ§in)
DEFAULT_PROJECT = "scratch_project"
HISTORY_DIR_NAME = "conversation_history"
LOG_DIR_NAME = "logs"
LOG_FILE_NAME = "agent.log"
LOG_MAX_BYTES = 5 * 1024 * 1024  # 5 MB
LOG_BACKUP_COUNT = 3


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Loglama Sistemi
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def setup_logger(log_dir: Path, log_level: str = "INFO") -> logging.Logger:
    """Dosya + konsol loglamasÄ± yapan logger kur.

    Log dosyasÄ±: <log_dir>/agent.log (RotatingFileHandler â€” 5MB Ã— 3 yedek)
    Konsol: sadece WARNING ve Ã¼stÃ¼ (terminali kirletmemek iÃ§in)
    """
    log_dir.mkdir(parents=True, exist_ok=True)
    log_file = log_dir / LOG_FILE_NAME

    logger = logging.getLogger("bio_ml_agent")
    logger.setLevel(getattr(logging, log_level.upper(), logging.INFO))

    # EÄŸer handler zaten eklenmiÅŸse tekrar ekleme
    if logger.handlers:
        return logger

    # â”€â”€ Dosya handler (her ÅŸeyi logla) â”€â”€
    file_handler = logging.handlers.RotatingFileHandler(
        log_file,
        maxBytes=LOG_MAX_BYTES,
        backupCount=LOG_BACKUP_COUNT,
        encoding="utf-8",
    )
    file_handler.setLevel(getattr(logging, log_level.upper(), logging.INFO))
    file_fmt = logging.Formatter(
        "%(asctime)s [%(levelname)-8s] [%(name)s] %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )
    file_handler.setFormatter(file_fmt)

    # â”€â”€ Konsol handler (sadece WARNING+) â”€â”€
    console_handler = logging.StreamHandler(sys.stderr)
    console_handler.setLevel(logging.WARNING)
    console_fmt = logging.Formatter(
        "%(asctime)s [%(levelname)s] %(message)s",
        datefmt="%H:%M:%S",
    )
    console_handler.setFormatter(console_fmt)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    logger.info("â•" * 60)
    logger.info("Logger baÅŸlatÄ±ldÄ± | seviye=%s | dosya=%s", log_level, log_file)
    logger.info("â•" * 60)

    return logger


# Global logger â€” main() iÃ§inde setup_logger() ile yapÄ±landÄ±rÄ±lacak
log = logging.getLogger("bio_ml_agent")

SYSTEM_PROMPT = """
You are a local Bioengineering ML Project Agent running on Linux.

GOAL
Turn the user's request into a reproducible ML project.

HARD RULES
- Use ONLY the tool protocol when performing actions (create files, run commands, web search/open).
- WRITE_FILE paths must be PROJECT-RELATIVE (e.g. src/train.py, data/raw/file.csv).
  DO NOT include "workspace/" or the project name in the path.
  The system automatically places files under workspace/<project>/.
  Example:
    CORRECT:   path: src/train.py
    CORRECT:   path: data/raw/diabetes.csv
    WRONG:     path: workspace/myproject/src/train.py
    WRONG:     path: myproject/src/train.py
- WRITE_FILE MUST use:
  path: relative/path.ext
  ---
  file content...
- BASH commands run from workspace/<project>/ directory.
  So use relative paths: python src/train.py (NOT python workspace/.../train.py)
- WEB_SEARCH is disabled unless user message includes: ALLOW_WEB_SEARCH

WORKFLOW
1) Clarify I/O + metrics (brief).
2) Find 2-5 candidate datasets (name+link+license/terms).
3) Pick dataset; download into data/raw/.
4) Create project structure and requirements.txt.
5) Implement baseline model in src/train.py.
6) **MULTI-MODEL COMPARISON** â€” Compare AT LEAST 3 models:
   - LogisticRegression, RandomForest, GradientBoosting, SVM, KNN
   - (For regression: LinearRegression, Ridge, RandomForest, GradientBoosting, SVR, KNN)
   - Use StandardScaler + Pipeline for each model.
   - Compute: accuracy, precision, recall, f1, roc_auc (classification)
              or r2, mae, rmse (regression).
   - Run 5-fold cross-validation for each model.
   - Print a comparison table and identify the BEST model.
   - You can use: `from utils.model_compare import compare_models`
     Example:
       comparator, results = compare_models(
           X_train, X_test, y_train, y_test,
           task_type="classification",
           output_dir="results/"
       )
   6.5) **HYPERPARAMETER OPTIMIZATION** (optional, if user requests or dataset is large):
   - Use: `from utils.hyperparameter_optimizer import optimize_model`
     Example:
       best_model, best_params, results = optimize_model(
           X_train, y_train,
           model_name="RandomForest",
           task_type="classification",
           method="random", n_iter=20
       )
7) Save results/comparison_results.json, results/comparison_report.md,
   and results/best_model.pkl (model is automatically saved by compare_models).
   The saved model can be loaded later:
     from utils.model_loader import load_and_predict
     predictions = load_and_predict("results/best_model.pkl", X_new)
8) **VISUALIZATION** â€” Generate plots and save as PNG to results/plots/:
   - Confusion Matrix (normal + normalized)
   - ROC Curve (binary or multi-class OvR)
   - Feature Importance (Gini or |coef|)
   - Correlation Matrix (heatmap)
   - Learning Curve (train vs validation)
   - Class Distribution (bar + donut)
   - You can use: `from utils.visualize import MLVisualizer`
     Example:
       viz = MLVisualizer(output_dir="results/plots")
       viz.plot_all(best_model, X_train, X_test, y_train, y_test,
                    feature_names=feature_cols, df=df)
   8.5) **DATA PREPROCESSING** (before training, if data quality is low):
   - Use: `from utils.preprocessor import DataPreprocessor, quick_preprocess, analyze_data_quality`
   - Quick quality check:
       report = analyze_data_quality(X, feature_names=feature_cols)
       print(report)
   - Full pipeline:
       pp = DataPreprocessor(
           impute_strategy="median",
           scale_method="standard",
           detect_outliers="iqr",
           remove_outliers=True,
           pca_components=10,  # optional dimensionality reduction
       )
       X_train_clean, y_train_clean = pp.fit_transform(X_train, y_train)
       X_test_clean = pp.transform(X_test)
       print(pp.summary_text())
   - Quick one-liner: X_clean = quick_preprocess(X, scale=True, pca=5)
9) Write report.md (include comparison table + plot references + model usage instructions) and README.md.

10) **RAG KNOWLEDGE SEARCH**:
    - Use the <RAG_SEARCH> tool to search past projects and reports in the workspace.
    - Example usage:
      <RAG_SEARCH>
      diabetes model comparison report
      </RAG_SEARCH>

11) **MULTI-AGENT COLLABORATION** (For complex tasks):
    - You are the Orchestrator. You can delegate specialized work to Sub-Agents.
    - Sub-Agents run in the same workspace but with focused prompts.
    - Use `from multi_agent import ask_data_engineer, ask_ml_engineer, ask_report_writer`
    - Example usage in a <PYTHON> block:
      ```python
      from multi_agent import ask_data_engineer, ask_ml_engineer
      
      # 1. Ask Data Engineer to clean data
      de_result = ask_data_engineer("Load data/raw/data.csv, handle NaN values, and save to data/processed/clean.csv")
      print("Data Engineer:", de_result)
      
      # 2. Ask ML Engineer to train models
      ml_result = ask_ml_engineer("Train RandomForest and SVM on data/processed/clean.csv. Save models to results/.")
      print("ML Engineer:", ml_result)
      ```
    - NOTE: Do not overuse sub-agents for simple tasks. Use them when tasks are logically separated.
11) **BIOENGINEERING TOOLKIT** (Specialized Biological / Medical Analysis):
    - You have a comprehensive suite of bio-focused analyzers. Import them from `bioeng_toolkit`:
      ```python
      from bioeng_toolkit import (
          ProteinAnalyzer, GenomicAnalyzer, WastewaterAnalyzer, 
          DrugDiscoveryHelper, MedicalImageHelper, BioSignalProcessor
      )
      ```
    - Use `ProteinAnalyzer("SEQ")` for amino acid stats, pI,, and GRAVY.
    - Use `GenomicAnalyzer("SEQ")` for DNA/RNA translation, ORFs, GC content.
    - Use `WastewaterAnalyzer({"pH": 7.2, "bod": 4.5, ...})` for water quality indexes and treatment rules.
    - Use `DrugDiscoveryHelper("SMILES_STRING")` for Lipinski's Rule of Five checks.
    - Use `BioSignalProcessor(np.random.randn(1000))` for EEG/EMG fast Fourier transforms and feature extractions.
    - Always output the `.summary()` or requested metrics from these classes into your text response.

Output language: Turkish (unless user asks otherwise).

TOOL PROTOCOL (ONE BLOCK ONLY):
<PYTHON>...</PYTHON>
<BASH>...</BASH>
<WEB_SEARCH>...</WEB_SEARCH>
<WEB_OPEN>...</WEB_OPEN>
<READ_FILE>...</READ_FILE>
<WRITE_FILE>...</WRITE_FILE>
<TODO>...</TODO>
"""

TOOL_TAGS = ["PYTHON", "BASH", "WEB_SEARCH", "WEB_OPEN", "READ_FILE", "WRITE_FILE", "TODO"]
TOOL_RE = re.compile(
    r"<(" + "|".join(TOOL_TAGS) + r")>\s*(.*?)\s*</\1>",
    re.DOTALL | re.IGNORECASE,
)

# Accept fenced code in ANY case, with optional language labels
FENCED_BASH_RE = re.compile(r"```(?:bash)?\s*(.*?)\s*```", re.DOTALL | re.IGNORECASE)
FENCED_PY_RE = re.compile(r"```(?:python|py)?\s*(.*?)\s*```", re.DOTALL | re.IGNORECASE)

# GÃ¼venlik desenleri â€” config.yaml'dan yÃ¼klenir, yoksa varsayÄ±lanlar kullanÄ±lÄ±r
DENY_PATTERNS = [
    r"\brm\b.*-rf\s+/",
    r":\(\)\s*{\s*:\s*\|\s*:\s*&\s*}\s*;\s*:",
    r"\bdd\b\s+if=/dev/zero\b",
    r"\bmkfs\.",
    r"\bshutdown\b",
    r"\breboot\b",
    r"\bkill\b\s+-9\s+1\b",
]

def _get_deny_patterns() -> list:
    """Config'den veya varsayÄ±lan DENY_PATTERNS'Ä± dÃ¶ndÃ¼rÃ¼r."""
    try:
        return _cfg().security.deny_patterns
    except Exception:
        return DENY_PATTERNS


def is_dangerous_bash(cmd: str) -> Optional[str]:
    patterns = _get_deny_patterns()
    for pat in patterns:
        if re.search(pat, cmd.strip()):
            log.warning("ğŸš« GÃœVENLÄ°K: Tehlikeli komut engellendi | pattern=%s | cmd=%s", pat, cmd.strip()[:100])
            return f"Blocked by denylist pattern: {pat}"
    return None


def safe_relpath(path: str) -> str:
    p = Path(path).expanduser()
    if p.is_absolute():
        log.warning("ğŸš« GÃœVENLÄ°K: Absolute path engellendi | path=%s", path)
        raise SecurityViolationError(
            f"Absolute path kullanÄ±lamaz: {path}",
            violation_type="absolute_path",
            suggestion="Workspace iÃ§inde relative path kullanÄ±n (Ã¶r: data/raw/file.csv).",
        )
    norm = Path(os.path.normpath(str(p)))
    if str(norm).startswith(".."):
        log.warning("ğŸš« GÃœVENLÄ°K: Path traversal engellendi | path=%s", path)
        raise SecurityViolationError(
            f"Path traversal engellendi: {path}",
            violation_type="path_traversal",
            suggestion="Ãœst dizinlere eriÅŸim yasaktÄ±r. Workspace iÃ§indeki dosyalarÄ± kullanÄ±n.",
        )
    return str(norm)


def current_project() -> str:
    try:
        return os.getenv("AGENT_PROJECT", _cfg().workspace.default_project)
    except Exception:
        return os.getenv("AGENT_PROJECT", DEFAULT_PROJECT)


def run_python(code: str, workspace: Path, timeout_s: int = 180) -> str:
    log.info("ğŸ PYTHON Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor | timeout=%ds | kod_uzunluk=%d karakter", timeout_s, len(code))
    log.debug("ğŸ PYTHON kod:\n%s", code[:500])
    code = textwrap.dedent(code).strip() + "\n"
    
    # KÃ¶k dizini PYTHONPATH'e ekle
    root_dir = Path(__file__).resolve().parent
    sys_path_injection = f"import sys\nsys.path.insert(0, r'{root_dir}')\n"
    code = sys_path_injection + code
    
    tmp = workspace / "_tmp_run.py"
    tmp.write_text(code, encoding="utf-8")
    try:
        start_time = time.time()
        res = subprocess.run(
            [sys.executable, str(tmp)],
            cwd=str(workspace),
            capture_output=True,
            text=True,
            timeout=timeout_s,
        )
        elapsed = time.time() - start_time
        out = (res.stdout or "") + (res.stderr or "")
        result = out.strip() if out.strip() else f"[python exit code: {res.returncode}] (no output)"
        log.info("ğŸ PYTHON tamamlandÄ± | sÃ¼re=%.2fs | exit_code=%d | Ã§Ä±ktÄ±_uzunluk=%d", elapsed, res.returncode, len(result))
        if res.returncode != 0:
            log.warning("ğŸ PYTHON hata ile bitti | exit_code=%d | stderr=%s", res.returncode, (res.stderr or "")[:300])
        return result
    except subprocess.TimeoutExpired:
        log.error("ğŸ PYTHON TIMEOUT | %ds aÅŸÄ±ldÄ±", timeout_s)
        raise ToolTimeoutError("PYTHON", timeout_s)
    except ToolTimeoutError:
        raise
    except Exception as e:
        log.error("ğŸ PYTHON beklenmeyen hata | %s", e, exc_info=True)
        raise ToolExecutionError("PYTHON", str(e), details=f"Kod uzunluÄŸu: {len(code)} karakter")
    finally:
        try:
            tmp.unlink(missing_ok=True)
        except Exception:
            pass


def run_bash(cmd: str, workspace: Path, timeout_s: int = 180) -> str:
    log.info("ğŸ’» BASH Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor | cmd=%s | timeout=%ds", cmd.strip()[:120], timeout_s)
    reason = is_dangerous_bash(cmd)
    if reason:
        log.warning("ğŸ’» BASH ENGELLENDÄ° | sebep=%s | cmd=%s", reason, cmd.strip()[:100])
        raise SecurityViolationError(
            f"Tehlikeli komut engellendi: {cmd.strip()[:80]}",
            violation_type="dangerous_command",
            details=reason,
            suggestion="Bu komut gÃ¼venlik politikasÄ± tarafÄ±ndan engellendi.",
        )
    try:
        start_time = time.time()
        res = subprocess.run(
            cmd,
            cwd=str(workspace),
            shell=True,
            capture_output=True,
            text=True,
            timeout=timeout_s,
            executable="/bin/bash",
        )
        elapsed = time.time() - start_time
        out = (res.stdout or "") + (res.stderr or "")
        result = out.strip() if out.strip() else f"[bash exit code: {res.returncode}] (no output)"
        log.info("ğŸ’» BASH tamamlandÄ± | sÃ¼re=%.2fs | exit_code=%d | Ã§Ä±ktÄ±_uzunluk=%d", elapsed, res.returncode, len(result))
        if res.returncode != 0:
            log.warning("ğŸ’» BASH hata ile bitti | exit_code=%d | cmd=%s", res.returncode, cmd.strip()[:100])
        return result
    except subprocess.TimeoutExpired:
        log.error("ğŸ’» BASH TIMEOUT | %ds aÅŸÄ±ldÄ± | cmd=%s", timeout_s, cmd.strip()[:100])
        raise ToolTimeoutError("BASH", timeout_s)
    except (ToolTimeoutError, SecurityViolationError):
        raise
    except Exception as e:
        log.error("ğŸ’» BASH beklenmeyen hata | %s", e, exc_info=True)
        raise ToolExecutionError("BASH", str(e), details=f"Komut: {cmd.strip()[:100]}")


def web_search(query: str) -> str:
    query = query.strip()
    if not query:
        log.warning("ğŸŒ WEB_SEARCH: BoÅŸ sorgu gÃ¶nderildi")
        raise ValidationError("query", "Web aramasÄ± iÃ§in sorgu boÅŸ olamaz.")
    log.info("ğŸŒ WEB_SEARCH baÅŸlatÄ±ldÄ± | sorgu=%s", query[:100])
    try:
        from ddgs import DDGS
        start_time = time.time()
        results = []
        with DDGS() as ddgs:
            for r in ddgs.text(query, max_results=10):
                results.append(
                    {"title": r.get("title"), "href": r.get("href"), "body": r.get("body")}
                )
        elapsed = time.time() - start_time
        log.info("ğŸŒ WEB_SEARCH tamamlandÄ± | sÃ¼re=%.2fs | sonuÃ§_sayÄ±sÄ±=%d", elapsed, len(results))
        return json.dumps(results, ensure_ascii=False, indent=2)
    except (AgentError,):
        raise
    except Exception as e:
        log.error("ğŸŒ WEB_SEARCH HATA | sorgu=%s | hata=%s", query[:80], e, exc_info=True)
        raise ToolExecutionError(
            "WEB_SEARCH", str(e),
            suggestion="ddgs paketini kurun: python -m pip install -U ddgs",
        )


def web_open(url: str) -> str:
    url = url.strip()
    if not (url.startswith("http://") or url.startswith("https://")):
        log.warning("ğŸ“– WEB_OPEN: GeÃ§ersiz URL | url=%s", url[:100])
        raise ValidationError(
            "url", f"GeÃ§ersiz URL: {url[:80]}",
            suggestion="URL http:// veya https:// ile baÅŸlamalÄ±dÄ±r.",
        )
    log.info("ğŸ“– WEB_OPEN baÅŸlatÄ±ldÄ± | url=%s", url[:150])
    try:
        import requests
        from bs4 import BeautifulSoup

        start_time = time.time()
        r = requests.get(url, timeout=25, headers={"User-Agent": "Mozilla/5.0"})
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        for tag in soup(["script", "style", "noscript"]):
            tag.extract()
        text = soup.get_text("\n")
        text = re.sub(r"\n{3,}", "\n\n", text).strip()
        elapsed = time.time() - start_time
        truncated = len(text) > 12000
        log.info("ğŸ“– WEB_OPEN tamamlandÄ± | sÃ¼re=%.2fs | status=%d | metin_uzunluk=%d | kÄ±rpÄ±ldÄ±=%s",
                 elapsed, r.status_code, len(text), truncated)
        return (text[:12000] + "\n\n[TRUNCATED]") if truncated else text
    except (AgentError,):
        raise
    except Exception as e:
        log.error("ğŸ“– WEB_OPEN HATA | url=%s | hata=%s", url[:100], e, exc_info=True)
        raise ToolExecutionError(
            "WEB_OPEN", str(e),
            details=f"URL: {url[:100]}",
            suggestion="URL'nin eriÅŸilebilir olduÄŸundan emin olun.",
        )


def read_file(payload: str, workspace: Path) -> str:
    rel = safe_relpath(payload.strip())
    p = workspace / rel
    if not p.exists():
        log.warning("ğŸ“„ READ_FILE: Dosya bulunamadÄ± | path=%s", rel)
        raise FileOperationError(
            "okuma", rel, "Dosya bulunamadÄ±.",
            suggestion=f"DosyanÄ±n var olduÄŸundan emin olun: {rel}",
        )
    if p.is_dir():
        log.warning("ğŸ“„ READ_FILE: KlasÃ¶r verildi | path=%s", rel)
        raise FileOperationError(
            "okuma", rel, "Verilen yol bir klasÃ¶r, dosya deÄŸil.",
            suggestion="Dosya yolunu belirtin, klasÃ¶r yolunu deÄŸil.",
        )
    data = p.read_text(encoding="utf-8", errors="replace")
    log.info("ğŸ“„ READ_FILE | path=%s | boyut=%d bytes", rel, len(data))
    return (data[:20000] + "\n\n[TRUNCATED]") if len(data) > 20000 else data


def sanitize_content(content: str) -> str:
    content_clean = re.sub(r"^\s*```[a-zA-Z0-9_-]*\s*$", "", content, flags=re.MULTILINE)
    content_clean = re.sub(r"^\s*```\s*$", "", content_clean, flags=re.MULTILINE)
    return content_clean.lstrip("\n")


def _strip_redundant_prefixes(rel: str, proj: str) -> str:
    """LLM'in yanlÄ±ÅŸlÄ±kla eklediÄŸi workspace/, proje adÄ± ve benzeri prefix'leri agresif olarak temizle.

    Ã–rnek dÃ¶nÃ¼ÅŸÃ¼mler:
      workspace/myproj/src/train.py                           â†’  src/train.py
      scratch_project/workspace/diabetes/src/train.py         â†’  src/train.py
      workspace/workspace/myproj/data/raw/file.csv            â†’  data/raw/file.csv
      myproj/workspace/myproj/results/plots/fig.png           â†’  results/plots/fig.png
      src/train.py                                            â†’  src/train.py  (deÄŸiÅŸmez)
      report.md                                               â†’  report.md     (deÄŸiÅŸmez)
    """
    _KNOWN_ROOTS = {"src", "data", "results", "docs", "models", "notebooks", "tests", "config", proj}
    _KNOWN_FILES = {"report.md", "README.md", "readme.md", "requirements.txt", "setup.py",
                    "todo.md", "report.txt", ".gitignore", "Makefile"}

    parts = list(Path(rel).parts)
    original = rel

    # DÃ¶ngÃ¼sel olarak Ã¶ndeki workspace ve proje_adi takÄ±larÄ±nÄ± temizle
    while parts and parts[0] in ("workspace", proj, "scratch_project", "Kanser_HÃ¼cresi_Analiz"):
        parts = parts[1:]

    # Kalan kÄ±smÄ±n iÃ§inde bilinen bir kÃ¶k varsa, ondan Ã¶ncesini de kes (Ã–rn: breast_cancer_classification/src/ -> src/)
    for i, part in enumerate(parts):
        if part in _KNOWN_ROOTS or part in _KNOWN_FILES:
            parts = parts[i:]
            break
            
    # EÄŸer sonuÃ§ boÅŸ kalÄ±rsa ve orijinali salt bir dosyaysa (Ã¶rn. train.py) onu geri ver
    cleaned = str(Path(*parts)) if parts else rel
    
    if cleaned != original:
        log.info("âœï¸ WRITE_FILE yol dÃ¼zeltildi: %s â†’ %s", original, cleaned)
        
    return cleaned


def write_file(payload: str, workspace: Path) -> str:
    raw = payload.strip()
    if "---" not in raw:
        log.warning("âœï¸ WRITE_FILE: Format hatasÄ± â€” '---' ayÄ±rÄ±cÄ± bulunamadÄ±")
        raise ValidationError(
            "WRITE_FILE format",
            "'---' ayÄ±rÄ±cÄ± bulunamadÄ±.",
            suggestion="DoÄŸru format: path: dosya.py\n---\niÃ§erik...",
        )
    head, content = raw.split("---", 1)
    m = re.search(r"^\s*path:\s*(.+)\s*$", head.strip(), re.MULTILINE)
    if not m:
        log.warning("âœï¸ WRITE_FILE: Format hatasÄ± â€” 'path:' satÄ±rÄ± bulunamadÄ±")
        raise ValidationError(
            "WRITE_FILE format",
            "'path: ...' satÄ±rÄ± eksik.",
            suggestion="Blok baÅŸÄ±nda 'path: dosya_adÄ±.py' satÄ±rÄ± olmalÄ±.",
        )

    rel = safe_relpath(m.group(1).strip())
    proj = current_project()
    # LLM'in yanlÄ±ÅŸlÄ±kla eklediÄŸi workspace/ veya proje adÄ± prefix'lerini temizle
    rel = _strip_redundant_prefixes(rel, proj)
    if not rel.startswith(proj + "/") and rel != proj:
        rel = f"{proj}/{rel}"

    p = workspace / rel
    p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(sanitize_content(content), encoding="utf-8")
    log.info("âœï¸ WRITE_FILE | path=%s | boyut=%d bytes", rel, p.stat().st_size)
    return f"[OK] Wrote {rel} ({p.stat().st_size} bytes)"


def append_todo(payload: str, workspace: Path) -> str:
    todo = workspace / f"{current_project()}/todo.md"
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    entry = payload.strip()
    if not entry:
        log.warning("ğŸ“ TODO: BoÅŸ iÃ§erik gÃ¶nderildi")
        raise ValidationError("TODO", "TODO bloÄŸu boÅŸ olamaz.")
    todo.parent.mkdir(parents=True, exist_ok=True)
    with todo.open("a", encoding="utf-8") as f:
        f.write(f"\n\n## {ts}\n{entry}\n")
    log.info("ğŸ“ TODO eklendi | dosya=%s | uzunluk=%d", todo.relative_to(workspace), len(entry))
    return f"[OK] Appended to {todo.relative_to(workspace)}"


@dataclass
class AgentConfig:
    model: str
    workspace: Path
    timeout: int
    max_steps: int
    history_dir: Path = field(default_factory=lambda: Path("conversation_history"))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  KonuÅŸma GeÃ§miÅŸi YÃ¶netimi
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _ensure_history_dir(history_dir: Path) -> None:
    """GeÃ§miÅŸ klasÃ¶rÃ¼nÃ¼ oluÅŸtur."""
    history_dir.mkdir(parents=True, exist_ok=True)


def generate_session_id() -> str:
    """Benzersiz oturum kimliÄŸi Ã¼ret."""
    return datetime.now().strftime("%Y%m%d_%H%M%S") + "_" + uuid.uuid4().hex[:8]


def save_conversation(history_dir: Path, session_id: str, messages: List[Dict[str, str]],
                      metadata: Optional[Dict] = None) -> Path:
    """KonuÅŸma geÃ§miÅŸini JSON dosyasÄ±na kaydet."""
    _ensure_history_dir(history_dir)
    filepath = history_dir / f"{session_id}.json"

    # Ä°lk kullanÄ±cÄ± mesajÄ±ndan Ã¶zet Ã§Ä±kar
    first_user_msg = ""
    for msg in messages:
        if msg["role"] == "user":
            first_user_msg = msg["content"][:120].replace("\n", " ")
            break

    data = {
        "session_id": session_id,
        "created_at": metadata.get("created_at", datetime.now().isoformat()) if metadata else datetime.now().isoformat(),
        "updated_at": datetime.now().isoformat(),
        "summary": first_user_msg,
        "message_count": len(messages),
        "messages": messages,
    }
    if metadata:
        data["metadata"] = metadata

    filepath.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    log.debug("ğŸ’¾ Oturum kaydedildi | session=%s | mesaj_sayÄ±sÄ±=%d", session_id, len(messages))
    return filepath


def load_conversation(history_dir: Path, session_id: str) -> Tuple[List[Dict[str, str]], Dict]:
    """KonuÅŸma geÃ§miÅŸini dosyadan yÃ¼kle. (messages, metadata) dÃ¶ndÃ¼rÃ¼r."""
    filepath = history_dir / f"{session_id}.json"
    if not filepath.exists():
        raise FileNotFoundError(f"Oturum bulunamadÄ±: {session_id}")

    data = json.loads(filepath.read_text(encoding="utf-8"))
    messages = data.get("messages", [])
    metadata = {
        "created_at": data.get("created_at", ""),
        "session_id": data.get("session_id", session_id),
    }
    return messages, metadata


def list_conversations(history_dir: Path, limit: int = 20) -> List[Dict]:
    """KayÄ±tlÄ± konuÅŸma oturumlarÄ±nÄ± listele (en yeniden en eskiye)."""
    _ensure_history_dir(history_dir)
    sessions = []
    for f in sorted(history_dir.glob("*.json"), reverse=True):
        try:
            data = json.loads(f.read_text(encoding="utf-8"))
            sessions.append({
                "session_id": data.get("session_id", f.stem),
                "created_at": data.get("created_at", "?"),
                "updated_at": data.get("updated_at", "?"),
                "summary": data.get("summary", "")[:80],
                "message_count": data.get("message_count", 0),
            })
        except (json.JSONDecodeError, KeyError):
            continue
        if len(sessions) >= limit:
            break
    return sessions


def delete_conversation(history_dir: Path, session_id: str) -> bool:
    """Bir konuÅŸma oturumunu sil."""
    filepath = history_dir / f"{session_id}.json"
    if filepath.exists():
        filepath.unlink()
        return True
    return False


def print_history_help():
    """GeÃ§miÅŸ yÃ¶netimi komutlarÄ±nÄ±n yardÄ±mÄ±nÄ± gÃ¶ster."""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘               ğŸ“œ KonuÅŸma GeÃ§miÅŸi KomutlarÄ±                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  /history           â†’ KayÄ±tlÄ± oturumlarÄ± listele            â•‘
â•‘  /load <session_id> â†’ Eski bir oturumu yÃ¼kle                â•‘
â•‘  /delete <session_id> â†’ Bir oturumu sil                     â•‘
â•‘  /new               â†’ Yeni oturum baÅŸlat (mevcut kaydedilir)â•‘
â•‘  /save              â†’ Mevcut oturumu ÅŸimdi kaydet           â•‘
â•‘  /info              â†’ Mevcut oturum bilgilerini gÃ¶ster       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


# Global LLM backend â€” main() iÃ§inde oluÅŸturulur, varsayÄ±lan Ollama
_llm_backend: Optional[LLMBackend] = None

# Global plugin manager
_plugin_manager: Optional[PluginManager] = None


def get_llm_backend(model: str = "") -> LLMBackend:
    """Aktif LLM backend'i dÃ¶ndÃ¼r (yoksa Ollama oluÅŸtur)."""
    global _llm_backend
    if _llm_backend is None:
        _llm_backend = OllamaBackend(model=model or "qwen2.5:latest")
    return _llm_backend


def set_llm_backend(backend: LLMBackend) -> None:
    """LLM backend'i deÄŸiÅŸtir."""
    global _llm_backend
    _llm_backend = backend
    log.info("ğŸ§  LLM backend deÄŸiÅŸtirildi: %s", backend)


def get_plugin_manager() -> PluginManager:
    """Plugin manager'Ä± dÃ¶ndÃ¼r (yoksa oluÅŸtur)."""
    global _plugin_manager
    if _plugin_manager is None:
        _plugin_manager = PluginManager()
    return _plugin_manager


def llm_chat(model: str, messages: List[Dict[str, str]]) -> str:
    log.info("ğŸ§  LLM isteÄŸi gÃ¶nderiliyor | model=%s | mesaj_sayÄ±sÄ±=%d", model, len(messages))
    start_time = time.time()
    try:
        backend = get_llm_backend(model)
        content = backend.chat(messages).strip()
        elapsed = time.time() - start_time
        log.info("ğŸ§  LLM yanÄ±t alÄ±ndÄ± | sÃ¼re=%.2fs | yanÄ±t_uzunluk=%d karakter", elapsed, len(content))
        log.debug("ğŸ§  LLM yanÄ±t (ilk 300 karakter): %s", content[:300])
        return content
    except LLMConnectionError:
        raise
    except Exception as e:
        elapsed = time.time() - start_time
        log.error("ğŸ§  LLM HATA | sÃ¼re=%.2fs | model=%s | hata=%s", elapsed, model, e, exc_info=True)
        raise LLMConnectionError(model, str(e))


def extract_tools(text: str) -> Tuple[List[Tuple[str, str]], str]:
    tools = []
    for m in TOOL_RE.finditer(text or ""):
        tools.append((m.group(1).upper(), m.group(2)))
    outside = TOOL_RE.sub("", text or "").strip()
    return tools, outside

def extract_tool(text: str) -> Tuple[Optional[str], Optional[str], str]:
    tools, outside = extract_tools(text)
    if not tools:
        return None, None, outside
    return tools[0][0], tools[0][1], outside


def normalize_user_message(s: str) -> str:
    s = s.replace("\r\n", "\n")
    lines = [ln.strip() for ln in s.split("\n")]
    lines = [ln for ln in lines if ln]
    return "\n".join(lines)


def autosave_web_outputs(cfg: AgentConfig, tool: str, out: str) -> None:
    proj = current_project()
    log_dir = cfg.workspace / proj / "datasets"
    log_dir.mkdir(parents=True, exist_ok=True)
    stamp = time.strftime("%Y%m%d_%H%M%S")
    fname = f"{tool.lower()}_{stamp}.json" if tool == "WEB_SEARCH" else f"{tool.lower()}_{stamp}.txt"
    (log_dir / fname).write_text(out, encoding="utf-8")


def main():
    # â”€â”€ 1. config.yaml'Ä± yÃ¼kle (varsayÄ±lanlar + yaml + env) â”€â”€
    global _app_cfg
    _app_cfg = load_config()
    app = _app_cfg

    # â”€â”€ 2. CLI argÃ¼manlarÄ± (en yÃ¼ksek Ã¶ncelik) â”€â”€
    parser = argparse.ArgumentParser(
        description="Bio-ML Agent â€” Yerel LLM destekli ML proje asistanÄ±",
        epilog="YapÄ±landÄ±rma: config.yaml > ortam deÄŸiÅŸkenleri > CLI argÃ¼manlarÄ±",
    )
    parser.add_argument("--model", default=app.agent.model,
                        help=f"Ollama model adÄ± (varsayÄ±lan: {app.agent.model})")
    parser.add_argument("--workspace", default=app.workspace.base_dir,
                        help=f"Ã‡alÄ±ÅŸma alanÄ± (varsayÄ±lan: {app.workspace.base_dir})")
    parser.add_argument("--timeout", type=int, default=app.agent.timeout,
                        help=f"Komut zaman aÅŸÄ±mÄ± saniye (varsayÄ±lan: {app.agent.timeout})")
    parser.add_argument("--max-steps", type=int, default=app.agent.max_steps,
                        help=f"Maks. adÄ±m sayÄ±sÄ± (varsayÄ±lan: {app.agent.max_steps})")
    parser.add_argument("--history-dir", default=app.history.directory,
                        help=f"KonuÅŸma geÃ§miÅŸi klasÃ¶rÃ¼ (varsayÄ±lan: {app.history.directory})")
    parser.add_argument("--load-session", default=None,
                        help="BaÅŸlangÄ±Ã§ta yÃ¼klenecek oturum ID'si")
    parser.add_argument("--log-level", default=app.logging.level,
                        choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
                        help=f"Log seviyesi (varsayÄ±lan: {app.logging.level})")
    parser.add_argument("--log-dir", default=app.logging.directory,
                        help=f"Log dosyalarÄ± klasÃ¶rÃ¼ (varsayÄ±lan: {app.logging.directory})")
    parser.add_argument("--backend", default="auto",
                        choices=["local", "remote", "auto"],
                        help="LLM backend modu: local (Ollama), remote (model adÄ±na gÃ¶re OpenAI/Anthropic/Gemini), auto (otomatik algÄ±la) (varsayÄ±lan: auto)")
    parser.add_argument("--config", default=None,
                        help="YapÄ±landÄ±rma dosyasÄ± yolu (varsayÄ±lan: config.yaml)")
    args = parser.parse_args()

    # â”€â”€ 3. CLI ile config farklÄ±ysa config'i gÃ¼ncelle â”€â”€
    if args.config:
        _app_cfg = load_config(config_path=args.config)
        app = _app_cfg

    # â”€â”€ 4. Logger'Ä± kur â”€â”€
    log_dir = Path(args.log_dir).expanduser().resolve()
    global log
    log = setup_logger(log_dir, args.log_level)

    log.info("ğŸ“‹ YapÄ±landÄ±rma yÃ¼klendi:\n%s", app.summary())

    cfg = AgentConfig(
        model=args.model,
        workspace=Path(args.workspace).expanduser().resolve(),
        timeout=args.timeout,
        max_steps=args.max_steps,
        history_dir=Path(args.history_dir).expanduser().resolve(),
    )
    cfg.workspace.mkdir(parents=True, exist_ok=True)
    _ensure_history_dir(cfg.history_dir)

    log.info("Agent baÅŸlatÄ±ldÄ± | model=%s | workspace=%s | timeout=%d | max_steps=%d",
             cfg.model, cfg.workspace, cfg.timeout, cfg.max_steps)

    # â”€â”€ LLM backend ve plugin sistemi â”€â”€
    backend_mode = getattr(args, 'backend', 'auto')
    backend = auto_create_backend(cfg.model, mode=backend_mode)
    set_llm_backend(backend)
    log.info("ğŸ§  LLM backend oluÅŸturuldu | backend=%s | model=%s | mod=%s",
             type(backend).__name__, cfg.model, backend_mode)
    pm = get_plugin_manager()
    plugins_dir = Path(__file__).resolve().parent / "plugins"
    loaded = pm.discover(plugins_dir)
    if loaded:
        log.info("ğŸ”Œ %d plugin yÃ¼klendi", loaded)
        print(f"ğŸ”Œ {loaded} plugin yÃ¼klendi: {', '.join(pm.tool_names)}")

    # â”€â”€ RAG Motoru baÅŸlat â”€â”€
    global rag
    rag = RAGEngine(workspace_dir=cfg.workspace)
    log.info("ğŸ” RAG Motoru baÅŸlatÄ±ldÄ± | db_dir=%s", rag.db_dir)

    # â”€â”€ Oturum baÅŸlat veya yÃ¼kle â”€â”€
    session_id = generate_session_id()
    session_metadata = {"created_at": datetime.now().isoformat()}
    system_prompt = SYSTEM_PROMPT + format_catalog_for_prompt() + pm.get_prompt_additions()
    messages: List[Dict[str, str]] = [{"role": "system", "content": system_prompt}]

    if args.load_session:
        try:
            messages, session_metadata = load_conversation(cfg.history_dir, args.load_session)
            session_id = session_metadata.get("session_id", session_id)
            log.info("Oturum yÃ¼klendi | session=%s | mesaj_sayÄ±sÄ±=%d", session_id, len(messages))
            print(f"ğŸ“‚ Oturum yÃ¼klendi: {session_id}")
            print(f"   Mesaj sayÄ±sÄ±: {len(messages)}")
        except FileNotFoundError as e:
            log.warning("Oturum yÃ¼klenemedi | session=%s | hata=%s", args.load_session, e)
            print(f"âŒ {e}")
            print("   Yeni oturum baÅŸlatÄ±lÄ±yor...\n")

    log.info("Yeni oturum baÅŸlatÄ±ldÄ± | session=%s", session_id)

    backend_label = type(backend).__name__.replace("Backend", "")
    print(f"ğŸ§  Bio-ML Agent ready | model={cfg.model} | backend={backend_label} | workspace={cfg.workspace}")
    print(f"ğŸ“œ Oturum ID: {session_id}")
    print(f"ğŸ’¾ GeÃ§miÅŸ klasÃ¶rÃ¼: {cfg.history_dir}")
    print(f"ğŸ“‹ Log klasÃ¶rÃ¼: {log_dir}")
    print(f"ğŸ”Œ Backend modu: {backend_mode} | Aktif: {backend_label}")
    print("Ã‡Ä±kmak iÃ§in: exit / quit | Komutlar: /history /load /new /save /delete /info /logs /rag /ragindex\n")

    while True:
        try:
            user = input(">>> ").strip()
        except (EOFError, KeyboardInterrupt):
            log.info("KullanÄ±cÄ± Ctrl+C/EOF ile Ã§Ä±kÄ±ÅŸ yaptÄ± | session=%s", session_id)
            print("\nğŸ’¾ Oturum kaydediliyor...")
            save_conversation(cfg.history_dir, session_id, messages, session_metadata)
            print(f"âœ… Kaydedildi: {session_id}")
            print("Ã‡Ä±kÄ±lÄ±yor.")
            break

        if not user:
            continue

        # â”€â”€ Ã‡Ä±kÄ±ÅŸ komutlarÄ± â”€â”€
        if user.lower() in {"exit", "quit"}:
            log.info("KullanÄ±cÄ± Ã§Ä±kÄ±ÅŸ yaptÄ± | session=%s | komut=%s", session_id, user.lower())
            print("ğŸ’¾ Oturum kaydediliyor...")
            save_conversation(cfg.history_dir, session_id, messages, session_metadata)
            print(f"âœ… Kaydedildi: {session_id}")
            break

        # â”€â”€ GeÃ§miÅŸ yÃ¶netimi komutlarÄ± â”€â”€
        if user.lower() == "/history":
            sessions = list_conversations(cfg.history_dir)
            if not sessions:
                print("\nğŸ“­ KayÄ±tlÄ± oturum bulunamadÄ±.\n")
            else:
                print(f"\nğŸ“œ KayÄ±tlÄ± Oturumlar ({len(sessions)} adet):")
                print("â”€" * 90)
                for i, s in enumerate(sessions, 1):
                    marker = " ğŸ‘ˆ (aktif)" if s["session_id"] == session_id else ""
                    print(f"  {i:2}. ğŸ†” {s['session_id']}{marker}")
                    print(f"      ğŸ“… {s['created_at'][:19]}  |  ğŸ’¬ {s['message_count']} mesaj")
                    print(f"      ğŸ“ {s['summary'][:70]}")
                    print()
                print("â”€" * 90)
                print("  YÃ¼klemek iÃ§in: /load <session_id>\n")
            continue

        if user.lower().startswith("/load "):
            target_id = user.split(" ", 1)[1].strip()
            try:
                # Mevcut oturumu Ã¶nce kaydet
                save_conversation(cfg.history_dir, session_id, messages, session_metadata)
                print(f"ğŸ’¾ Mevcut oturum kaydedildi: {session_id}")

                messages, session_metadata = load_conversation(cfg.history_dir, target_id)
                session_id = session_metadata.get("session_id", target_id)
                print(f"âœ… Oturum yÃ¼klendi: {session_id}")
                print(f"   Mesaj sayÄ±sÄ±: {len(messages)}")

                # Son birkaÃ§ mesajÄ± gÃ¶ster
                user_msgs = [m for m in messages if m["role"] == "user"
                             and not m["content"].startswith("TOOL_OUTPUT")]
                if user_msgs:
                    print(f"\n   ğŸ“ Son kullanÄ±cÄ± mesajÄ±:")
                    print(f"      \"{user_msgs[-1]['content'][:100]}...\"\n")
            except FileNotFoundError as e:
                print(f"âŒ {e}\n")
            continue

        if user.lower().startswith("/delete "):
            target_id = user.split(" ", 1)[1].strip()
            if target_id == session_id:
                print("âŒ Aktif oturumu silemezsiniz! Ã–nce /new ile yeni oturum baÅŸlatÄ±n.\n")
            elif delete_conversation(cfg.history_dir, target_id):
                print(f"ğŸ—‘ï¸  Oturum silindi: {target_id}\n")
            else:
                print(f"âŒ Oturum bulunamadÄ±: {target_id}\n")
            continue

        if user.lower() == "/new":
            # Mevcut oturumu kaydet, yenisini baÅŸlat
            log.info("Yeni oturum baÅŸlatÄ±lÄ±yor | eski_session=%s", session_id)
            save_conversation(cfg.history_dir, session_id, messages, session_metadata)
            print(f"ğŸ’¾ Mevcut oturum kaydedildi: {session_id}")

            session_id = generate_session_id()
            session_metadata = {"created_at": datetime.now().isoformat()}
            messages = [{"role": "system", "content": SYSTEM_PROMPT}]
            log.info("Yeni oturum oluÅŸturuldu | yeni_session=%s", session_id)
            print(f"ğŸ†• Yeni oturum baÅŸlatÄ±ldÄ±: {session_id}\n")
            continue

        if user.lower() == "/save":
            path = save_conversation(cfg.history_dir, session_id, messages, session_metadata)
            print(f"ğŸ’¾ Oturum kaydedildi: {path}\n")
            continue

        if user.lower() == "/info":
            user_msg_count = sum(1 for m in messages if m["role"] == "user"
                                and not m["content"].startswith("TOOL_OUTPUT"))
            asst_msg_count = sum(1 for m in messages if m["role"] == "assistant")
            print(f"\nğŸ“Š Oturum Bilgileri:")
            print(f"   ğŸ†” Oturum ID  : {session_id}")
            print(f"   ğŸ“… OluÅŸturulma: {session_metadata.get('created_at', '?')[:19]}")
            print(f"   ğŸ’¬ Toplam mesaj: {len(messages)}")
            print(f"   ğŸ‘¤ KullanÄ±cÄ±   : {user_msg_count} mesaj")
            print(f"   ğŸ¤– Asistan     : {asst_msg_count} mesaj")
            print(f"   ğŸ’¾ GeÃ§miÅŸ yolu : {cfg.history_dir / f'{session_id}.json'}")
            print()
            continue

        if user.lower() in {"/help", "/h"}:
            print_history_help()
            continue

        if user.lower().startswith("/logs"):
            # Son loglarÄ± gÃ¶ster
            parts = user.split()
            tail_lines = 30
            if len(parts) > 1:
                try:
                    tail_lines = int(parts[1])
                except ValueError:
                    pass
            log_file = log_dir / LOG_FILE_NAME
            if log_file.exists():
                lines = log_file.read_text(encoding="utf-8", errors="replace").splitlines()
                show = lines[-tail_lines:] if len(lines) > tail_lines else lines
                print(f"\nğŸ“‹ Son {len(show)} log satÄ±rÄ± ({log_file}):")
                print("â”€" * 90)
                for line in show:
                    print(f"  {line}")
                print("â”€" * 90)
                print(f"  Toplam: {len(lines)} satÄ±r | GÃ¶sterilen: son {len(show)} satÄ±r")
                print(f"  Daha fazla gÃ¶rmek iÃ§in: /logs <satÄ±r_sayÄ±sÄ±>\n")
            else:
                print(f"\nğŸ“­ Log dosyasÄ± henÃ¼z oluÅŸturulmamÄ±ÅŸ: {log_file}\n")
            continue

        if user.lower() == "/ragindex":
            print("ğŸ” Workspace indeksleniyor. LÃ¼tfen bekleyin...")
            count = rag.index_workspace()
            print(f"âœ… Ä°ndeksleme tamamlandÄ±. {count} dosya iÅŸlendi.\n")
            continue

        if user.lower().startswith("/rag "):
            query = user.split(" ", 1)[1].strip()
            print(f"ğŸ” RAG aramasÄ± yapÄ±lÄ±yor: '{query}'")
            results = rag.search(query)
            if not results:
                print("ğŸ“­ EÅŸleÅŸen sonuÃ§ bulunamadÄ±.\n")
            else:
                for i, r in enumerate(results, 1):
                    print(f"\n[{i}] ğŸ“„ {r['source']} (Mesafe: {r['distance']:.4f})")
                    print("â”€" * 40)
                    print(r['document'])
                    print("â”€" * 40)
                print()
            continue

        # â”€â”€ Normal agent akÄ±ÅŸÄ± â”€â”€
        log.info("ğŸ‘¤ KullanÄ±cÄ± mesajÄ± alÄ±ndÄ± | uzunluk=%d | session=%s", len(user), session_id)
        log.debug("ğŸ‘¤ KullanÄ±cÄ± mesajÄ±: %s", user[:300])
        user = normalize_user_message(user)
        allow_web = ("ALLOW_WEB_SEARCH" in user.upper())
        if allow_web:
            log.info("ğŸŒ Web aramasÄ± etkinleÅŸtirildi (ALLOW_WEB_SEARCH)")

        mproj = re.search(r"(?i)\bPROJECT\s*:\s*([a-z0-9_\-]+)", user)
        project = mproj.group(1) if mproj else DEFAULT_PROJECT
        os.environ["AGENT_PROJECT"] = project
        (cfg.workspace / project).mkdir(parents=True, exist_ok=True)
        log.info("ğŸ“ Aktif proje: %s", project)

        try:
            from memory_manager import memory
            mem_context = memory.get_context_string(user, n_results=2)
            if mem_context:
                enriched_user = f"{mem_context}\n\n[Mevcut GÃ¶rev/Soru]:\n{user}"
                messages.append({"role": "user", "content": enriched_user})
                log.info("ğŸ§  RAG HafÄ±zasÄ± (%d sonuÃ§) mesaja eklendi", 2)
            else:
                messages.append({"role": "user", "content": user})
        except Exception as e:
            log.warning("HafÄ±za yÃ¶neticisi hatasÄ±: %s", e)
            messages.append({"role": "user", "content": user})

        # Her kullanÄ±cÄ± mesajÄ±ndan sonra otomatik kaydet
        save_conversation(cfg.history_dir, session_id, messages, session_metadata)

        for step in range(cfg.max_steps):
            log.info("ğŸ”„ AdÄ±m %d/%d baÅŸlÄ±yor", step + 1, cfg.max_steps)
            
            try:
                from llm_backend import summarize_memory
                backend_for_mem = auto_create_backend(cfg.model)
                messages = summarize_memory(messages, backend_for_mem, threshold=20)
            except Exception as e:
                log.warning("Bellek Ã¶zetleme adÄ±mÄ± atlatÄ±ldÄ±: %s", e)
            
            with Spinner(f"ğŸ§  LLM dÃ¼ÅŸÃ¼nÃ¼yor (adÄ±m {step + 1}/{cfg.max_steps})"):
                assistant = llm_chat(cfg.model, messages)

            tools_to_run, outside = extract_tools(assistant)

            if not tools_to_run:
                py_m = FENCED_PY_RE.search(assistant)
                bash_m = FENCED_BASH_RE.search(assistant)
                if py_m and (not bash_m or len(py_m.group(1)) >= len(bash_m.group(1))):
                    tools_to_run = [("PYTHON", py_m.group(1))]
                    outside = FENCED_PY_RE.sub("", assistant).strip()
                    log.info("ğŸ”§ Fenced code block'tan PYTHON tool algÄ±landÄ±")
                elif bash_m:
                    tools_to_run = [("BASH", bash_m.group(1))]
                    outside = FENCED_BASH_RE.sub("", assistant).strip()
                    log.info("ğŸ”§ Fenced code block'tan BASH tool algÄ±landÄ±")
                else:
                    log.info("ğŸ’¬ Agent dÃ¼z metin yanÄ±tÄ± verdi (tool yok) | adÄ±m=%d", step + 1)
                    print("\nğŸ¤– Agent:\n", assistant)
                    messages.append({"role": "assistant", "content": assistant})
                    
                    try:
                        from memory_manager import memory
                        memory.store_interaction(session_id, user, assistant)
                        log.info("ğŸ§  EtkileÅŸim kalÄ±cÄ± hafÄ±zaya (RAG) kaydedildi")
                    except Exception as e:
                        log.warning("HafÄ±za kaydetme hatasÄ±: %s", e)
                        
                    # Asistan cevabÄ±ndan sonra otomatik kaydet
                    save_conversation(cfg.history_dir, session_id, messages, session_metadata)
                    break

            if outside:
                log.warning("âš ï¸ Tool bloÄŸu dÄ±ÅŸÄ±nda metin vardÄ± | dÄ±ÅŸ_metin_uzunluk=%d", len(outside))
                print("\nâš ï¸ UyarÄ±: Tool bloÄŸu dÄ±ÅŸÄ±nda metin vardÄ±; yine de tool Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor.\n")

            messages.append({"role": "assistant", "content": assistant})
            
            all_outputs = []
            break_loop = False

            for tool, payload in tools_to_run:
                log.info("ğŸ”§ Tool algÄ±landÄ±: %s | payload_uzunluk=%d", tool, len(payload or ""))
                try:
                    if tool == "PYTHON":
                        # PYTHON kodlarÄ±nÄ± projenin kendi klasÃ¶rÃ¼nde Ã§alÄ±ÅŸtÄ±r
                        py_cwd = cfg.workspace / project
                        py_cwd.mkdir(parents=True, exist_ok=True)
                        with Spinner("ğŸ Python Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor"):
                            out = run_python(payload, py_cwd, timeout_s=cfg.timeout)
                    elif tool == "BASH":
                        # BASH komutlarÄ±nÄ± projenin kendi klasÃ¶rÃ¼nde Ã§alÄ±ÅŸtÄ±r
                        bash_cwd = cfg.workspace / project
                        bash_cwd.mkdir(parents=True, exist_ok=True)
                        with Spinner("ğŸ’» Bash Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor"):
                            out = run_bash(payload, bash_cwd, timeout_s=cfg.timeout)
                    elif tool == "WEB_SEARCH":
                        if not allow_web and not _cfg().security.allow_web_search:
                            out = "[BLOCKED] WEB_SEARCH is disabled. To enable for this request, include: ALLOW_WEB_SEARCH"
                        else:
                            with Spinner("ğŸŒ Web'de aranÄ±yor"):
                                out = web_search(payload)
                    elif tool == "WEB_OPEN":
                        with Spinner("ğŸ“– Sayfa okunuyor"):
                            out = web_open(payload)
                    elif tool == "READ_FILE":
                        out = read_file(payload, cfg.workspace)
                    elif tool == "WRITE_FILE":
                        out = write_file(payload, cfg.workspace)
                    elif tool == "TODO":
                        out = append_todo(payload, cfg.workspace)
                    elif tool == "RAG_SEARCH":
                        with Spinner("ğŸ” RAG'da aranÄ±yor"):
                            results = rag.search(payload)
                            if not results:
                                out = "[RAG_SEARCH] SonuÃ§ bulunamadÄ±."
                            else:
                                out = "[RAG_SEARCH] Bulunan metinler:\n\n"
                                for i, r in enumerate(results, 1):
                                    out += f"--- Kaynak: {r['source']} (Mesafe: {r['distance']:.4f}) ---\n"
                                    out += f"{r['document']}\n\n"
                    elif pm.get(tool):
                        with Spinner(f"ğŸ”Œ {tool} Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor"):
                            out = pm.execute(tool, payload, cfg.workspace)
                    else:
                        out = f"[ERROR] Unknown tool: {tool}"

                except LLMConnectionError as e:
                    log.error("ğŸ§  LLM baÄŸlantÄ± hatasÄ± | %s", e)
                    print(f"\n{e.user_message()}")
                    print("\nâ³ 5 saniye sonra tekrar denenecek...\n")
                    time.sleep(5)
                    try:
                        with Spinner("ğŸ§  LLM tekrar deneniyor"):
                            assistant = llm_chat(cfg.model, messages)
                        messages.append({"role": "assistant", "content": assistant})
                        save_conversation(cfg.history_dir, session_id, messages, session_metadata)
                    except LLMConnectionError as e2:
                        log.error("ğŸ§  LLM tekrar deneme baÅŸarÄ±sÄ±z | %s", e2)
                        print(f"\n{e2.user_message()}")
                        print("\nâš ï¸ LLM'e baÄŸlanÄ±lamÄ±yor. LÃ¼tfen Ollama servisini kontrol edin.\n")
                        save_conversation(cfg.history_dir, session_id, messages, session_metadata)
                    break_loop = True
                    break

                except SecurityViolationError as e:
                    log.warning("ğŸ”’ GÃ¼venlik ihlali | %s", e)
                    print(f"\n{e.user_message()}")
                    out = e.tool_output()

                except ToolTimeoutError as e:
                    log.error("â° Zaman aÅŸÄ±mÄ± | %s", e)
                    print(f"\n{e.user_message()}")
                    out = e.tool_output()

                except (ToolExecutionError, FileOperationError, ValidationError) as e:
                    log.error("ğŸ› ï¸ Tool hatasÄ± | %s", e)
                    print(f"\n{e.user_message()}")
                    out = e.tool_output()

                except AgentError as e:
                    log.error("âŒ Agent hatasÄ± | %s", e)
                    print(f"\n{e.user_message()}")
                    out = e.tool_output()

                except Exception as e:
                    log.error("ğŸ’¥ Beklenmeyen hata | tool=%s | %s", tool, e, exc_info=True)
                    print(f"\nâŒ Beklenmeyen hata: {e}")
                    print(f"   ğŸ’¡ Ã–neri: Bu hatayÄ± /logs komutuyla inceleyebilirsiniz.\n")
                    out = f"[UNEXPECTED_ERROR] {type(e).__name__}: {e}"

                if tool in {"WEB_SEARCH", "WEB_OPEN"} and not out.startswith("["):
                    autosave_web_outputs(cfg, tool, out)

                log.info("ğŸ› ï¸ Tool tamamlandÄ± | tool=%s | Ã§Ä±ktÄ±_uzunluk=%d", tool, len(out))
                print(f"\nğŸ› ï¸ {tool} output:\n{out}\n")
                all_outputs.append((tool, out))

            if break_loop:
                break
            
            user_msg = ""
            for t, o in all_outputs:
                user_msg += f"TOOL_OUTPUT ({t}):\n{o}\n\n"
            user_msg += "Continue. If done, answer normally (no tool)."
            
            messages.append({
                "role": "user",
                "content": user_msg
            })

            # Her tool adÄ±mÄ±ndan sonra otomatik kaydet
            save_conversation(cfg.history_dir, session_id, messages, session_metadata)
        else:
            log.warning("âš ï¸ Maksimum adÄ±m sayÄ±sÄ±na ulaÅŸÄ±ldÄ± (%d) | session=%s", cfg.max_steps, session_id)
            print("\nâš ï¸ Max steps reached. Task may be incomplete.\n")
            save_conversation(cfg.history_dir, session_id, messages, session_metadata)


if __name__ == "__main__":
    main()
